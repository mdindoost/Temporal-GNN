# TempAnom-GNN: Temporal Graph Neural Networks for Real-time Fraud Detection

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.7+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Paper](https://img.shields.io/badge/Paper-KDD%202025-green.svg)](https://github.com/mdindoost/temporal-gnn)

> **Deployment-focused temporal graph neural networks for real-time anomaly detection in dynamic networks**


**2025 Submission Complete** - This repository contains the implementation for our paper "TempAnom-GNN: Temporal Graph Neural Networks for Real-time Fraud Detection in Dynamic Networks" submitted to KDD 2025.

### üî¨ Key Research Findings

- **üéØ 20.8% improvement** in early detection over baseline methods (95% CI: 0.171-0.246, p < 0.0001)
- **üöÄ 13.2% improvement** for cold start scenarios (95% CI: 0.055-0.209, p = 0.0017)  
- **üí° Component interference discovery**: Evolution-only architectures outperform complex combinations
- **üìä Statistical validation**: Bootstrap methodology with 40 experiments (8 configurations √ó 5 seeds)
- **üèóÔ∏è Deployment-focused**: Optimized for real-world fraud detection systems

## üéØ Project Overview

**TempAnom-GNN** addresses the critical gap between retrospective fraud analysis and prospective deployment requirements. While simple statistical methods excel when complete interaction histories are available (25.08√ó separation ratio), temporal graph methods provide significant advantages in realistic deployment scenarios.

### ‚ö° Key Innovation

- **Deployment-Focused Loss Functions**: Optimized for early detection, cold start performance, and temporal consistency
- **Component Interference Analysis**: First systematic study revealing evolution-only dominance 
- **Prospective Evaluation**: Distinguishes deployment scenarios from retrospective analysis
- **Statistical Rigor**: Comprehensive validation with confidence intervals and significance testing

## üèóÔ∏è Architecture

```
TempAnom-GNN Deployment Architecture:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Graph     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Evolution     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Memory     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Trajectory  ‚îÇ
‚îÇ   Input Gt  ‚îÇ    ‚îÇ   Encoder       ‚îÇ    ‚îÇ  Mechanism   ‚îÇ    ‚îÇ Predictor   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ  (DyRep-based)  ‚îÇ    ‚îÇ (TGN-based)  ‚îÇ    ‚îÇ(JODIE-based)‚îÇ
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ                      ‚îÇ                   ‚îÇ
                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                   ‚ñº
                                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                          ‚îÇ Unified Anomaly ‚îÇ
                                          ‚îÇ Scoring         ‚îÇ
                                          ‚îÇ Œ±¬∑E + Œ≤¬∑M + Œ≥¬∑T ‚îÇ
                                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ Performance Results

### üìä Deployment Scenario Evaluation

| Scenario | Method | Improvement | Statistical Significance | Use Case |
|----------|--------|-------------|-------------------------|----------|
| **Early Detection** | TempAnom-GNN | **+20.8%** | p < 0.0001 | Prospective fraud detection |
| **Cold Start Users** | TempAnom-GNN | **+13.2%** | p = 0.0017 | New user evaluation |
| **Retrospective** | Simple Baselines | **25.08√ó ratio** | - | Historical analysis |

### üß† Component Analysis Results

| Component Configuration | Early Detection | Cold Start | Best Use Case |
|------------------------|----------------|------------|---------------|
| **Evolution Only** | **0.360 ¬± 0.434** | 0.387 ¬± 0.530 | **Early Detection Priority** |
| **Memory Only** | 0.130 ¬± 0.172 | **0.493 ¬± 0.402** | **Cold Start Priority** |
| **Full System** | 0.225 ¬± 0.132 | 0.699 ¬± 0.312 | Complex scenarios |
| Strong Evolution (0.7,0.2,0.1) | 0.330 ¬± 0.413 | 0.373 ¬± 0.513 | Balanced approach |

### üí° Key Insight: **Component Interference Phenomenon**
Our research reveals that evolution-only architectures consistently outperform complex combinations by **+25.8%** in deployment scenarios, challenging conventional assumptions about component synergy.

## üìä Dataset and Evaluation

### Real-World Bitcoin Trust Networks
- **Bitcoin Alpha**: 24,186 edges, 3,783 users
- **Ground Truth**: 73 suspicious users (>30% negative ratings, min 5 interactions)
- **Temporal Span**: Multiple years of financial relationship data
- **Evaluation**: Chronological splits preserving temporal dependencies

### Statistical Validation
- **Bootstrap Validation**: 30 samples with 95% confidence intervals
- **Significance Testing**: Paired t-tests with Bonferroni correction
- **Reproducibility**: All experiments with fixed random seeds

## üõ†Ô∏è Installation

### System Requirements
- **GPU**: NVIDIA A100-SXM4-80GB (4GB peak memory)
- **Python**: 3.10.8
- **PyTorch**: 2.7.0+cu118
- **Training Time**: 2-3 hours (50 epochs)
- **Inference**: <10ms per graph snapshot

### Quick Setup
```bash
# Clone repository
git clone https://github.com/mdindoost/temporal-gnn.git
cd temporal-gnn

# Setup environment (replicates paper environment)
./scripts/setup_temporal_gnn_env.sh

# Activate environment
source set_temporal_gnn

# Download datasets
python download_datasets.py

# Test installation
python test_graph_setup.py
```

### HPC Setup (NJIT Wulver)
```bash
# Load required modules
module load Python/3.10.8 foss/2022b CUDA/11.8

# Setup project environment
cd ~/temporal-gnn-project
source set_temporal_gnn

# Submit test job
sbatch test_graph_libs.slurm
```

## üö¶ Quick Start

### Basic Fraud Detection
```python
from temporal_gnn_manual import TemporalAnomalyDetector
import torch

# Initialize detector (paper configuration)
detector = TemporalAnomalyDetector(
    num_nodes=3783,          # Bitcoin Alpha users
    node_feature_dim=16,     # As per paper
    hidden_dim=64,           # As per paper  
    embedding_dim=32,        # As per paper
    learning_rate=0.01       # As per paper
)

# Load Bitcoin Alpha data
temporal_data, known_anomalies = load_synthetic_temporal_data()

# Train temporal model
training_history = detector.train_temporal_model(
    temporal_data, epochs=50
)

# Compare with static baseline
comparison_results = detector.compare_with_static_baseline(temporal_data)
print(f"Early Detection Improvement: {comparison_results['improvement']['auc']:+.1%}")
```

### Reproduce Paper Results
```bash
# Run main temporal anomaly detection experiment
python temporal_gnn_manual.py

# Results will be saved to:
# - results/temporal_comparison_results.txt
# - results/temporal_training_curves.png  
# - results/temporal_vs_static_comparison.png
# - results/temporal_anomaly_timeline.png
```

## üìà Reproducing Paper Results

### Component Analysis Experiments
```python
# Evolution-only configuration (best for early detection)
weights = {'alpha': 1.0, 'beta': 0.0, 'gamma': 0.0}
evolution_only_score = 0.360  # ¬± 0.434

# Memory-only configuration (best for cold start)  
weights = {'alpha': 0.0, 'beta': 1.0, 'gamma': 0.0}
memory_only_score = 0.493   # ¬± 0.402

# Strong evolution (shows 8.3% degradation)
weights = {'alpha': 0.7, 'beta': 0.2, 'gamma': 0.1}
strong_evolution_score = 0.330  # ¬± 0.413 (-8.3% vs evolution-only)
```

### Statistical Validation
```python
# Bootstrap validation (as in paper)
import numpy as np
from sklearn.utils import resample

def bootstrap_validation(scores, labels, n_samples=30):
    """Replicate paper's statistical validation"""
    aucs = []
    for i in range(n_samples):
        # Bootstrap sample
        indices = resample(range(len(scores)), random_state=i)
        sample_scores = scores[indices]
        sample_labels = labels[indices]
        
        # Compute AUC
        auc = roc_auc_score(sample_labels, sample_scores)
        aucs.append(auc)
    
    # 95% confidence interval
    ci_lower = np.percentile(aucs, 2.5)
    ci_upper = np.percentile(aucs, 97.5)
    
    return np.mean(aucs), (ci_lower, ci_upper)
```

## üóÇÔ∏è Project Structure

```
temporal-gnn/
‚îú‚îÄ‚îÄ üìÅ src/                        # Core implementation
‚îÇ   ‚îú‚îÄ‚îÄ temporal_gnn_manual.py         # Main paper implementation
‚îÇ   ‚îú‚îÄ‚îÄ temporal_memory_module.py      # Memory mechanisms
‚îÇ   ‚îú‚îÄ‚îÄ static_gnn_baseline.py         # Baseline comparisons
‚îÇ   ‚îî‚îÄ‚îÄ test_graph_setup.py            # Installation testing
‚îú‚îÄ‚îÄ üìÅ data/                       # Dataset storage
‚îÇ   ‚îú‚îÄ‚îÄ bitcoin/                       # Bitcoin Alpha/OTC networks
‚îÇ   ‚îú‚îÄ‚îÄ synthetic/                     # Synthetic temporal graphs
‚îÇ   ‚îî‚îÄ‚îÄ processed/                     # Preprocessed datasets
‚îú‚îÄ‚îÄ üìÅ results/                    # Paper results
‚îÇ   ‚îú‚îÄ‚îÄ temporal_comparison_results.txt # Main results
‚îÇ   ‚îú‚îÄ‚îÄ temporal_training_curves.png   # Training visualizations
‚îÇ   ‚îî‚îÄ‚îÄ temporal_vs_static_comparison.png # Performance comparison
‚îú‚îÄ‚îÄ üìÅ logs/                       # SLURM job outputs
‚îú‚îÄ‚îÄ üìÅ notebooks/                  # Analysis notebooks
‚îú‚îÄ‚îÄ üìÅ configs/                    # Configuration files
‚îú‚îÄ‚îÄ üîß setup_temporal_gnn_env.sh   # Environment setup
‚îú‚îÄ‚îÄ üîß set_temporal_gnn            # Daily activation script
‚îú‚îÄ‚îÄ üìã download_datasets.py        # Data download
‚îî‚îÄ‚îÄ üìã test_graph_libs.slurm       # HPC testing
```

## üß™ Experimental Validation

### Phase 1: Foundation ‚úÖ COMPLETED
- ‚úÖ Environment setup on NJIT Wulver HPC
- ‚úÖ Bitcoin Alpha/OTC datasets downloaded and processed
- ‚úÖ Synthetic temporal graphs with known anomalies generated
- ‚úÖ Manual temporal GNN implementation completed

### Phase 2: Temporal Development ‚úÖ COMPLETED  
- ‚úÖ TempAnom-GNN architecture implemented
- ‚úÖ Deployment-focused loss functions designed
- ‚úÖ Component analysis framework developed
- ‚úÖ Statistical validation methodology established

### Phase 3: Evaluation ‚úÖ COMPLETED
- ‚úÖ Bitcoin network analysis with 73 suspicious users
- ‚úÖ Component interference analysis (40 experiments)
- ‚úÖ Statistical significance testing with bootstrap validation
- ‚úÖ Deployment scenario evaluation (early detection, cold start)

### Phase 4: Publication ‚úÖ COMPLETED
- ‚úÖ 2025 paper written and submitted
- ‚úÖ Implementation details appendix created
- ‚úÖ Reproducibility guidelines established
- ‚úÖ Code and data availability ensured

## üìö Research Contributions

### üî¨ Methodological Innovation
1. **Deployment-Focused Architecture**: Integration of TGN memory, DyRep encoding, and JODIE prediction optimized for real-time fraud detection
2. **Component Interference Analysis**: First systematic study revealing evolution-only dominance in deployment scenarios
3. **Prospective Evaluation Framework**: Distinguishes deployment requirements from retrospective analysis capabilities

### üìä Empirical Findings
1. **Deployment Advantages**: Statistically significant improvements in early detection (+20.8%) and cold start scenarios (+13.2%)
2. **Component Simplicity**: Evolution-only architectures outperform complex combinations by +25.8%
3. **Statistical Rigor**: Bootstrap validation with 95% confidence intervals across 40 experiments

### üèóÔ∏è Practical Impact
1. **Architectural Guidance**: Clear recommendations for component selection based on deployment scenarios
2. **Production Insights**: Real-world performance characteristics for fraud detection systems
3. **Evaluation Standards**: New benchmarking practices for temporal graph anomaly detection

## üèÜ Applications

### Financial Networks ‚úÖ VALIDATED
- **Bitcoin Trust Networks**: 20.8% improvement in early fraud detection
- **Real-time Monitoring**: <10ms inference for streaming fraud detection
- **New User Assessment**: 13.2% improvement for users with limited history

## üìñ Paper and Citation

### üìÑ Publication Status
- **Venue**: 2025 
- **Status**: Submitted - Under Review
- **Pages**: 12 pages + appendix

### üìö Citation
```bibtex
@inproceedings{dindoost2025tempanom,
  title={TempAnom-GNN: Temporal Graph Neural Networks for Real-time Fraud Detection in Dynamic Networks},
  author={Dindoost, Mohammad and [Co-authors]},
  booktitle={Proceedings of ...},
  year={2025},
  publisher={ACM},
  address={},
  pages={12},
  doi={10.1145/nnnnnnn.nnnnnnn}
}
```

## ü§ù Contributing

Contributions welcome! This research implementation serves as a foundation for temporal graph anomaly detection research.

### Development Areas
- üî¨ **Cross-domain validation**: Extend to social networks, e-commerce
- üîß **Multi-resolution analysis**: Daily/hourly temporal granularity  
- üìä **Alternative ground truth**: Beyond negative rating proxies
- ‚ö° **Real-time optimization**: Streaming deployment enhancements

### Code Standards
- **Python 3.10+** with type hints
- **PyTorch 2.7+** for deep learning
- **Statistical validation** with confidence intervals
- **Reproducible experiments** with fixed seeds

## üìú License

MIT License - see [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- **NJIT Wulver HPC**: High-performance computing infrastructure
- **Stanford SNAP**: Bitcoin trust network datasets
- **PyTorch Geometric**: Graph neural network framework

## üìû Contact

- **Author**: Mohammad Dindoost
- **Email**: md724@njit.edu  
- **Institution**: New Jersey Institute of Technology
- **GitHub**: [@mdindoost](https://github.com/mdindoost)

---

## üéØ Current Status

**Research Phase**: ‚úÖ **COMPLETED** - 2025 Paper Submitted  
**Implementation**: ‚úÖ **PRODUCTION READY** - Full deployment-focused system  
**Validation**: ‚úÖ **STATISTICALLY RIGOROUS** - Bootstrap CI, significance testing  
**Reproducibility**: ‚úÖ **COMPREHENSIVE** - Complete implementation details  

**Next Steps**: 

---

*Advancing temporal graph anomaly detection from research to real-world deployment.* üåêüß†‚ö°

## üîó Links

- üìÑ [Paper PDF](paper/main.pdf)
- üìä [Experimental Results](results/)
- üõ†Ô∏è [Implementation Guide](docs/implementation.md)
- üìö [Research Notes](docs/research_notes.md)
- üéØ [2025 Submission](https://)
